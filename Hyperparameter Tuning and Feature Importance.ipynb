{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "155c4bfe",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "In machine learning, the components of the model you're running is called a parameter. This is very different than how you use the term in statistics, where a parameter just means a statistic for a population, so the context is important when you encounter the word parameter!\n",
    "\n",
    "There are parameters that the model will handle itself, based on your training data. There is nothing you can do with these. But some parameters, you can mess around with to help improve your model fit. Parameters that are adjustable are called hyperparameters.\n",
    "\n",
    "The process of \"messing with\" hyperparameters is called tuning. Think about a tune-up for your car. You want to fix the little things so that overall, your car runs better and smoother. That's exactly what is going on with tuning your machine learning model as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9e61a2",
   "metadata": {},
   "source": [
    "#### parameters that are adjustable are called hyperparameters. the components of a model I'm running is called a parameter; very different from statistics, where it's a statistic for a population. the processing of messing with hyperparameters is called tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88405b32",
   "metadata": {},
   "source": [
    "#### Hyperparameters for Decision Trees and Random Forests\n",
    "There are four hyperparameters for decision trees and random forests that are important:\n",
    "\n",
    "Maximum depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fca288",
   "metadata": {},
   "source": [
    "#### Maximum Depth\n",
    "The maximum depth is how far down the \"roots\" of your tree go. How many nodes do you allow?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d584a623",
   "metadata": {},
   "source": [
    "#### Root node -> Node -> leaves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847d4d59",
   "metadata": {},
   "source": [
    "#### 2   Number of Estimators\n",
    "The number of estimators is how many trees that make up a forest. Generally, the more trees you have, the better your accuracy will be, but more trees also increases computation time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e291ce",
   "metadata": {},
   "source": [
    "#### 3 Maximum Number of Features\n",
    "A feature is the decision points, or branches, on the tree. You can set a limit as to how many are allowed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a194d3d",
   "metadata": {},
   "source": [
    "#### 4 Minimum Number of Samples\n",
    "The minimum number of samples is how many data points are being sorted at each feature. This has a minimum instead of a maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4387b05d",
   "metadata": {},
   "source": [
    "#### minimum number of samples for a leaf aka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675ebafb",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning in Python\n",
    "Now that you know a little bit about hyperparameter tuning, you'll go ahead and do it in Python! Huzzah!\n",
    "\n",
    "Load in Libraries\n",
    "In addition to everything else you used for random forests, you'll also need the following library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e534ff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "#also the following for a random forest\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ea6ca19",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01017388",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris.drop('species', axis=1)\n",
    "y = iris['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83702afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01956276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=500, random_state=76)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=500, random_state=76)\n",
    "forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44980656",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  0  0]\n",
      " [ 0 11  2]\n",
      " [ 0  0 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        19\n",
      "  versicolor       1.00      0.85      0.92        13\n",
      "   virginica       0.87      1.00      0.93        13\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.96      0.95      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forestPredictions = forest.predict(x_test)\n",
    "print(confusion_matrix(y_test, forestPredictions))\n",
    "print(classification_report(y_test, forestPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93fd712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8cede25",
   "metadata": {},
   "source": [
    "#### Number of Estimators\n",
    "The first thing you want to do is determine how many trees you should be using, which is the number of estimators. The code below will help you find the best number of estimators based on the accuracy of the model. Remember that an accuracy of 1 is the highest you can get, so the closer you get to one, the better.\n",
    "\n",
    "You can create an array that contains the most likely number of estimators, which is what is shown in the first line. While you could put any numbers in this array, these typically get used frequently in ML. Then you'll create an empty list named results that will end up filled using a for loop!\n",
    "\n",
    "And lastly, on to the for loop itself! This iterates over your n_estimators_array and creates a random forest for each, prints out the accuracy for each, and finally adds it to your results list. So you don't have to test everything manually! The very last line in the for loop prints out each result as it becomes available. Depending on how fast your computer is, this code may take a minute (you are doing 11 random forests, after all!) and you can see the results come up in real time. Pretty cool!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d52201f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 0.9111111111111111\n",
      "4 : 0.9555555555555556\n",
      "5 : 0.9333333333333333\n",
      "8 : 0.9555555555555556\n",
      "10 : 0.9777777777777777\n",
      "20 : 0.9555555555555556\n",
      "50 : 0.9555555555555556\n",
      "75 : 0.9555555555555556\n",
      "100 : 0.9555555555555556\n",
      "250 : 0.9555555555555556\n",
      "500 : 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "n_estimators_array = [1, 4, 5, 8, 10, 20, 50, 75, 100, 250, 500]\n",
    "results = []\n",
    "for n in n_estimators_array:\n",
    "    forest = RandomForestClassifier(n_estimators=n, random_state=76)\n",
    "    forest.fit(x_train, y_train)\n",
    "    result = accuracy_score(y_test, forest.predict(x_test))\n",
    "    results.append(result) \n",
    "    print(n, ':', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5085e896",
   "metadata": {},
   "source": [
    "#### make sure to import accuracy_score from sklearn.metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a191e5",
   "metadata": {},
   "source": [
    "#### So it looks like the best accuracy arises when you use only 10 trees instead of the standard 500! Good to know.\n",
    "\n",
    "If you wanted a visual representation of this, that can be done too with your good old plt() function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2efb0209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ff0affcac0>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(n_estimators_array, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d237f413",
   "metadata": {},
   "source": [
    "#### You really get a sense from this graph that things have completely stagnated before 100 trees, so it certainly is a waste of processing power to request 500!\n",
    "\n",
    "Tuning the Remaining Three\n",
    "If you're wondering if there is an easier way to find the best hyperparameter values without having to go through each, then guess what? There is! You can automate it and find em' all in one whack with the RandomizedSearchCV library. Although you'll be doing this just with random forests right now, this library will work with any algorithm in the sklearn library! If you're not convinced yet that a randomized grid search is the bee's knees, then to sweeten the pot, they've thrown in cross-validation for the accuracy calculations as well!\n",
    "\n",
    "Below you are creating lists with all the hyperparameter values you want to trial. There is one for each of the remaining three features, named: max_features, max_depth, and min_samples_leaf. Then, you'll create a dictionary with the hyperparameter names as the keys and the list variables as the values. This is called a grid and is aptly named random_grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596900e3",
   "metadata": {},
   "source": [
    "#### to repeat - RandomizedSearchCV library. Although you'll be doing this just with random forests right now, this library will work with any algorithm in the sklearn library! If you're not convinced yet that a randomized grid search is the, then to sweeten the pot, they've thrown in cross-validation for the accuracy calculations as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b34db1b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': ['auto', None, 'log2'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, None], 'min_samples_leaf': [1, 2, 4]}\n"
     ]
    }
   ],
   "source": [
    "# Number of features to consider at every split\n",
    "max_features = ['auto', None, 'log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [10, 20, 30, 40, 50, 60, 70, 80, 90, None]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "random_grid = {'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e17c9e",
   "metadata": {},
   "source": [
    "#### So nothing has actually happened yet - but you're prepared for the next move, which is to initialize one random forest for every one of those hyperparameters in the random_grid. Since you know that you only want ten trees, the first line sets up a random forest model with that.\n",
    "\n",
    "The next line of code gives you a random search of the random_grid you created using the function RandomizedSearchCV(). The arguments for that function include the estimator=, which is what you've named your latest iteration of the random forest with only ten estimators, the param_distributions= argument, which is where you plug in the random_grid dictionary, n_iter=, which is the number of iterations, or times to complete the random forest, and lastly, the cv= argument, which allows you to choose how many folds you'd like in your cross validation. The random_state= argument is not required to run code, but including it means that your results should be the same as those in the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01a4e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=10)\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 90, cv = 3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415e02a9",
   "metadata": {},
   "source": [
    "#### With that created, it's time to fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96e3fb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestClassifier(n_estimators=10),\n",
       "                   n_iter=90,\n",
       "                   param_distributions={'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, None],\n",
       "                                        'max_features': ['auto', None, 'log2'],\n",
       "                                        'min_samples_leaf': [1, 2, 4]},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed99c366",
   "metadata": {},
   "source": [
    "#### It basically just tells you what it did, which is not particularly helpful. What would be helpful is knowing which hyperparameter produced the best accuracy. But that isn't possible, is it?\n",
    "\n",
    "It is! Try this line of code out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46506a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 2, 'max_features': None, 'max_depth': 50}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bd4c3f",
   "metadata": {},
   "source": [
    "#### This means that the model with the best accuracy has at least 4 samples per leaf, leaves the max features setting on auto, and has a maximum depth of 30 decision points. Pretty nifty! Now all you need to do is run one last random forest that actually has those parameters! This is relatively plug-and-play here, since in your random grid search code, you used approximately the same names."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a6723d",
   "metadata": {},
   "source": [
    "#### note my output says to have a maximum depth of 50 - not 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3aa6fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=30, min_samples_leaf=4, n_estimators=10)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=10, min_samples_leaf=4, max_features=\"auto\", max_depth=30)\n",
    "forest.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6f894f",
   "metadata": {},
   "source": [
    "#### running the code above just tells you the details of the model. But if you want the details (and of course you want the details!) you can use the same prediction and classification report info as before, but with your new and improved model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "398fd4e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19  0  0]\n",
      " [ 0 12  1]\n",
      " [ 0  0 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        19\n",
      "  versicolor       1.00      0.92      0.96        13\n",
      "   virginica       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.97      0.97        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forestPredictions = forest.predict(x_test)\n",
    "print(confusion_matrix(y_test, forestPredictions))\n",
    "print(classification_report(y_test, forestPredictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e705db",
   "metadata": {},
   "source": [
    "### looks good. overall accuracy is 95% weighted. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b941a",
   "metadata": {},
   "source": [
    "#### you plug in the random_grid dictionary after param_distributions\n",
    "#the very first thing you want to do when hyperparameter tuning is find the number of estimators. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392a7a9f",
   "metadata": {},
   "source": [
    "#### Feature Importance\n",
    "When you have more than one x variable in a machine learning model, how do you know which one of them is important? Are they all equally important? Do some help predict y more than others? If you were doing regression, you could find out by looking at the individual p values related to the variable, or you could do a stepwise regression of some sort to tease out how much each matters. But these options don't exist for machine learning. However, something called feature importance does.\n",
    "\n",
    "Each variable in machine learning can also be referred to as a feature. So, determining the feature importance just means that you can figure out which variable makes more difference to the prediction of the y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6c01b0",
   "metadata": {},
   "source": [
    "#### Feature Importance in Python\n",
    "It's a pretty quick and easy line of code to get feature importance! They are outputs of your model, and so you just need to call them in a format that is useful. You'll create a new variable called feature_importances that is formatted as a pandas series, using the function pd.Series(). Then, you can call forest.feature_importances_, which by default is created when you run forest. Lastly, for readability, you can index it with the argument index= and put in x.columns so that the name of the column names in your dataset show on the left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec68585d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    0.001153\n",
       "sepal_width     0.040525\n",
       "petal_length    0.408658\n",
       "petal_width     0.549664\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = pd.Series(forest.feature_importances_, index=x.columns)\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1178c82",
   "metadata": {},
   "source": [
    "#### The bigger, the better for feature importance. Wouldn't it be nice to see each of them in order of feature importance, rather than in column order? Well, that can be arranged! The sort_values() function will sort them. The inplace=True argument, like always, makes this change permanent, and ascending=False means that this goes from largest to smallest, which is exactly what you'd like to see! Then all you need to do is print it out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c68050aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "petal_width     0.549664\n",
      "petal_length    0.408658\n",
      "sepal_width     0.040525\n",
      "sepal_length    0.001153\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "feature_importances.sort_values(inplace=True, ascending=False)\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3438ea60",
   "metadata": {},
   "source": [
    "#### If you're someone visual, you can also graph this. A simple bar graph will do if you aren't showing it off to anyone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b11f9924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importances.plot(kind='barh', figsize=(7,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136d40a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
